import os
import argparse
import signal
import sys
from typing import Dict, Any
from prompt_toolkit import PromptSession
from prompt_toolkit.history import FileHistory
from prompt_toolkit.auto_suggest import AutoSuggestFromHistory
from prompt_toolkit.key_binding import KeyBindings
from prompt_toolkit.styles import Style
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_deepseek import ChatDeepSeek
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.chat_models.base import BaseChatModel
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ç³»ç»Ÿé…ç½®
CHROMA_DIR = "chroma_db_hardware"
HISTORY_FILE = os.path.expanduser("~/.qa_history")  # ä¿å­˜åœ¨ç”¨æˆ·ä¸»ç›®å½•ä¸‹

# ç¡®ä¿å†å²æ–‡ä»¶ç›®å½•å­˜åœ¨
os.makedirs(os.path.dirname(HISTORY_FILE), exist_ok=True)

# æ¨¡å‹é…ç½®
EMBEDDING_MODEL = "text-embedding-ada-002"  # OpenAI åµŒå…¥æ¨¡å‹
OPENAI_MODEL = "gpt-3.5-turbo"  # OpenAI å¯¹è¯æ¨¡å‹
DEEPSEEK_MODEL = "deepseek-chat"  # DeepSeek å¯¹è¯æ¨¡å‹
TEMPERATURE = 0  # æ¸©åº¦å‚æ•°ï¼š0è¡¨ç¤ºæœ€ç¡®å®šæ€§çš„å›ç­”ï¼Œ1è¡¨ç¤ºæœ€å…·åˆ›é€ æ€§
TOP_K_RESULTS = 5  # æ£€ç´¢æ—¶è¿”å›çš„æœ€ç›¸å…³æ–‡æ¡£æ•°é‡

def get_llm(model_type: str = "openai") -> BaseChatModel:
    """è·å–è¯­è¨€æ¨¡å‹å®ä¾‹
    
    Args:
        model_type: æ¨¡å‹ç±»å‹ï¼Œå¯é€‰ 'openai' æˆ– 'deepseek'
        
    Returns:
        è¯­è¨€æ¨¡å‹å®ä¾‹
    """
    if model_type == "openai":
        if not os.getenv("OPENAI_API_KEY"):
            api_key = input("è¯·è¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥: ").strip()
            os.environ["OPENAI_API_KEY"] = api_key
            
        return ChatOpenAI(
            model=OPENAI_MODEL,
            temperature=TEMPERATURE,
            streaming=True,  # å¯ç”¨æµå¼è¾“å‡º
        )
    elif model_type == "deepseek":
        if not os.getenv("DEEPSEEK_API_KEY"):
            api_key = input("è¯·è¾“å…¥æ‚¨çš„DeepSeek APIå¯†é’¥: ").strip()
            os.environ["DEEPSEEK_API_KEY"] = api_key
            
        return ChatDeepSeek(
            model=DEEPSEEK_MODEL,
            temperature=TEMPERATURE,
            streaming=True,  # å¯ç”¨æµå¼è¾“å‡º
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")

def init_qa_system(model_type: str = "openai") -> Dict[str, Any]:
    """åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿ
    
    Args:
        model_type: æ¨¡å‹ç±»å‹ï¼Œå¯é€‰ 'openai' æˆ– 'deepseek'
    
    Returns:
        åŒ…å«å‘é‡å­˜å‚¨å’ŒQAé“¾çš„å­—å…¸
    """
    # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    embeddings = OpenAIEmbeddings(
        model=EMBEDDING_MODEL,
        show_progress_bar=True
    )
    
    # åŠ è½½å‘é‡å­˜å‚¨
    vectorstore = Chroma(
        persist_directory=CHROMA_DIR,
        embedding_function=embeddings
    )
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = vectorstore.as_retriever(
        search_kwargs={"k": TOP_K_RESULTS}
    )
    
    # åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
    llm = get_llm(model_type)
    
    # åˆ›å»ºæç¤ºæ¨¡æ¿
    prompt_template = """ä½ æ˜¯ä¸€ä¸ªç¡¬ä»¶å·¥ç¨‹å¸ˆï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä»æ–‡æ¡£ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯å¹¶ç”Ÿæˆå›ç­”ã€‚

é—®é¢˜: {question}

ç›¸å…³æ–‡æ¡£å†…å®¹:
{context}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç”Ÿæˆä¸“ä¸šã€å‡†ç¡®çš„å›ç­”ï¼Œå¹¶åœ¨å›ç­”æœ€åç»™å‡ºç›¸åº”æ–‡æ¡£åã€ç« èŠ‚å’Œé¡µç ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚

å›ç­”:"""

    PROMPT = PromptTemplate(
        template=prompt_template,
        input_variables=["context", "question"]
    )
    
    # åˆ›å»ºQAé“¾
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": PROMPT}
    )
    
    return {
        "vectorstore": vectorstore,
        "qa_chain": qa_chain
    }

def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="ç¡¬ä»¶æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")
    parser.add_argument(
        "--model",
        type=str,
        choices=["openai", "deepseek"],
        default="openai",
        help="é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹ (é»˜è®¤: openai)"
    )
    return parser.parse_args()

def format_source_info(doc: Any) -> str:
    """æ ¼å¼åŒ–æ–‡æ¡£æ¥æºä¿¡æ¯
    
    Args:
        doc: æ–‡æ¡£å¯¹è±¡
        
    Returns:
        æ ¼å¼åŒ–åçš„æ¥æºä¿¡æ¯å­—ç¬¦ä¸²
    """
    source = doc.metadata.get('source', 'æœªçŸ¥æ¥æº')
    return source

def signal_handler(signum, frame):
    """å¤„ç†ä¸­æ–­ä¿¡å·"""
    print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼")
    sys.exit(0)

def create_keybindings() -> KeyBindings:
    """åˆ›å»ºè‡ªå®šä¹‰é”®ç»‘å®š
    
    Returns:
        KeyBindings å®ä¾‹
    """
    kb = KeyBindings()
    
    @kb.add('enter')
    def _(event):
        """å¤„ç†å›è½¦é”®ï¼šç›´æ¥æäº¤æŸ¥è¯¢"""
        buff = event.current_buffer
        if buff.text.strip():  # å¦‚æœæœ‰å†…å®¹æ‰æäº¤
            buff.validate_and_handle()
    
    @kb.add('escape', 'enter')  # Alt + Enter
    def _(event):
        """å¤„ç† Alt+Enterï¼šæ’å…¥æ¢è¡Œ"""
        event.current_buffer.insert_text('\n')
    
    return kb

def run_qa_interface(model_type: str = "openai") -> None:
    """è¿è¡Œé—®ç­”æ¥å£
    
    Args:
        model_type: æ¨¡å‹ç±»å‹ï¼Œå¯é€‰ 'openai' æˆ– 'deepseek'
    """
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    
    # å®šä¹‰æç¤ºæ ·å¼
    style = Style.from_dict({
        'prompt': '#00aa00 bold',
        'continuation': '#666666',
    })
    
    # åˆå§‹åŒ–æç¤ºä¼šè¯
    session = PromptSession(
        history=FileHistory(HISTORY_FILE),
        auto_suggest=AutoSuggestFromHistory(),
        enable_history_search=True,
        key_bindings=create_keybindings(),
        style=style,
        multiline=True,  # å¯ç”¨å¤šè¡Œæ¨¡å¼
        prompt_continuation=lambda width, line_number, is_soft_wrap: '... > ',
    )
    
    print(f"\nğŸ¤– ç¡¬ä»¶æ–‡æ¡£é—®ç­”ç³»ç»Ÿ (ä½¿ç”¨ {model_type} æ¨¡å‹)")
    print("- æŒ‰å›è½¦æäº¤é—®é¢˜")
    print("- æŒ‰ Alt+å›è½¦ æ¢è¡Œç»§ç»­è¾“å…¥")
    print("- è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
    print("- è¾“å…¥ 'help' è·å–å¸®åŠ©")
    print("- æŒ‰ Ctrl+C éšæ—¶é€€å‡º")
    print("- ä½¿ç”¨ä¸Šä¸‹ç®­å¤´é”®æµè§ˆå†å²è®°å½•")
    print("- ä½¿ç”¨ Ctrl+R æœç´¢å†å²è®°å½•")
    
    qa_system = init_qa_system(model_type)
    qa_chain = qa_system["qa_chain"]
    
    while True:
        try:
            # ä½¿ç”¨ prompt_toolkit è·å–å¤šè¡Œè¾“å…¥
            query = session.prompt(
                ">>> ",
                style=style
                ).strip()
            
            if not query:
                continue
                
            if query.lower() in ["exit", "quit"]:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼")
                break
                
            if query.lower() == "help":
                print("\nğŸ“– å¸®åŠ©ä¿¡æ¯:")
                print("- æ‚¨å¯ä»¥è¯¢é—®æœ‰å…³ç¡¬ä»¶çš„ä»»ä½•é—®é¢˜")
                print("- æŒ‰å›è½¦æäº¤é—®é¢˜")
                print("- æŒ‰ Alt+å›è½¦ æ¢è¡Œç»§ç»­è¾“å…¥")
                print("- ç³»ç»Ÿä¼šä»æ–‡æ¡£ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯å¹¶ç”Ÿæˆå›ç­”")
                print("- æ¯ä¸ªå›ç­”éƒ½ä¼šæ˜¾ç¤ºä¿¡æ¯æ¥æº")
                print("- æŒ‰ Ctrl+C éšæ—¶é€€å‡º")
                print("- ä½¿ç”¨ä¸Šä¸‹ç®­å¤´é”®æµè§ˆå†å²è®°å½•")
                print("- ä½¿ç”¨ Ctrl+R æœç´¢å†å²è®°å½•")
                continue
                
            try:
                result = qa_chain.invoke({"query": query})
                print(f"\nğŸ§  å›ç­”:\n{result['result']}")
                
                # è·å–å»é‡åçš„å‚è€ƒæ¥æº
                if result["source_documents"]:
                    sources = {format_source_info(doc) for doc in result["source_documents"]}
                    print("\nğŸ“„ å‚è€ƒæ¥æº:")
                    for source in sorted(sources):  # æ’åºä»¥ä¿æŒç¨³å®šçš„è¾“å‡ºé¡ºåº
                        print(f" - {source}")
            except Exception as e:
                print(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
        except KeyboardInterrupt:
            signal_handler(signal.SIGINT, None)
        except EOFError:  # å¤„ç† Ctrl+D
            print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼")
            break

if __name__ == "__main__":
    args = parse_args()
    try:
        run_qa_interface(args.model)
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}") 